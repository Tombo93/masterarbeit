{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17480,"status":"ok","timestamp":1685636575715,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"b8VrPnXsbSe8","outputId":"c99c8adf-0ec3-400a-c60c-5ea8ebd140c9"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1685636575715,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"eArkaKWQcTBk"},"outputs":[],"source":["ISICDATA = '/content/drive/MyDrive/ISIC'\n","TF_LOGDIR = '/content/drive/MyDrive/runs'\n","METADATA = 'metadata_combined.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["installer = !pip install torchmetrics\n","installer"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6581,"status":"ok","timestamp":1685636582294,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"SlU5sM2gYe9w"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.utils.tensorboard import SummaryWriter\n","import pandas as pd\n","import os\n","from PIL import Image\n","\n","from torchmetrics import MetricCollection\n","from torchmetrics.classification import Accuracy, AUROC, Precision\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"od3qR-exdko8"},"source":["DataSet Implementation"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685636582295,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"NF9hFZKgfIXM"},"outputs":[],"source":["class FamilyHistoryDataSet(torch.utils.data.Dataset):\n","  def __init__(self, metadata, root_dir, transforms=None, data_col=None, ylabel_col=None):\n","    self.root_dir = root_dir\n","    self.transforms = transforms\n","    self.annotations = pd.read_csv(os.path.join(root_dir, metadata))\n","    self.xdata_col = self.annotations.columns.get_loc(data_col)\n","    self.ylabel_col = self.annotations.columns.get_loc(ylabel_col)\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  def __getitem__(self, index):\n","    img_path = os.path.join(self.root_dir, self.annotations.iloc[index, self.xdata_col])\n","    image = Image.open(img_path)\n","    y_label = torch.tensor(int(self.annotations.iloc[index, self.ylabel_col]))\n","    if self.transforms:\n","      image = self.transforms(image)\n","    return (image, y_label)\n","\n","  def get_splits(self, splits=[0.8, 0.2]):\n","    train_split = round(len(self.annotations)*splits[0])\n","    test_split = len(self.annotations) - train_split\n","    return (train_split, test_split)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"B_fz8qat5-ee"},"source":["Hyperparameters, Dataloader & Split"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1032,"status":"ok","timestamp":1685636836797,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"3vbdLd9N1O5q"},"outputs":[],"source":["learning_rate = 1e-3\n","batch_size = 256\n","epochs = 100\n","img_crop_size = 85\n","# data\n","ISIC_MEAN = [1.2721, 0.3341, -0.0479]\n","ISIC_STD = [0.2508, 0.2654, 0.3213]\n","\n","dataset = FamilyHistoryDataSet(\n","    metadata='family_history.csv',\n","    root_dir = ISICDATA,\n","    transforms=T.Compose(\n","        [T.CenterCrop(img_crop_size),\n","    \tT.ToTensor(),\n","        T.Normalize(ISIC_MEAN, ISIC_STD)]\n","        ),\n","    data_col='filename',\n","    ylabel_col='family_history')\n","\n","train_split, test_split = dataset.get_splits()\n","train_set, test_set = torch.utils.data.random_split(dataset, [train_split, test_split])\n","train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"M3b3VVYS5vvM"},"source":["\n","Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1685636855142,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"ul7GBMY55D3M","outputId":"5dab01e0-6f1b-4ad1-bb53-d7f0fcc4f4ac"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, n_classes, in_features):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_features, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(6480, 32)\n","        self.fc2 = nn.Linear(32, n_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=True)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# model params\n","n_classes = 2\n","in_features = 3\n","\n","model = CNN(n_classes, in_features)\n","model.to(device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A_kngCdY55yC"},"source":["Training"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1685636917876,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"ltoR863nPn-9"},"outputs":[],"source":["def basic_training_loop(train_loader, model, loss_func, optimizer, metrics, scaler, device):\n","    for batch_idx, (data, labels) in enumerate(train_loader):\n","        data = data.to(device)\n","        labels = labels.to(device)\n","        with autocast():\n","            prediction = model(data)\n","            loss = loss_func(prediction, labels)\n","        \n","        _, pred_labels = prediction.max(dim=1)\n","        metrics.update(pred_labels, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","        if batch_idx % 10 == 0:\n","            print(f'batch_idx: {batch_idx}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cN2Hzlzu77Lx"},"source":["Evaluation"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":206,"status":"ok","timestamp":1685636813669,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"uxh0fuuJ76XJ"},"outputs":[],"source":["def metrics_validation(test_loader, model, metrics, device):\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_idx, (x, y) in enumerate(test_loader):\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","            pred = model(x)\n","            _, pred_labels = pred.max(dim=1)\n","            metrics.update(pred_labels, y)\n","            if batch_idx % 10 == 0:\n","                print(f'batch_idx: {batch_idx}')\n","    model.train()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"poE0W2pS5yO1"},"source":["Loss + Optimization Algorithm"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":226,"status":"ok","timestamp":1685636871226,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"3RFcz92vQmZk"},"outputs":[],"source":["class OptimizationLoop:\n","    def __init__(self, params) -> None:\n","        self.n_epochs = params['n_epochs']\n","        self.training = params['train_loop']\n","        self.validation = params['validation_loop']\n","        \n","        self.model = params['model']\n","        self.train_loader = params['train_loader']\n","        self.test_loader = params['test_loader']\n","        self.loss_func = params['loss']\n","        self.optimizer = params['optim']\n","        self.device = params['device']\n","        self.train_metrics = params['metrics']['train'].to(self.device)\n","        self.valid_metrics = params['metrics']['valid'].to(self.device)\n","        self.scaler = GradScaler()\n","        self.writer = SummaryWriter(TF_LOGDIR)\n","\n","    def optimize(self) -> None:\n","        for epoch in range(self.n_epochs):\n","            self.training(\n","                self.train_loader, self.model,\n","                self.loss_func, self.optimizer,\n","                self.train_metrics, self.scaler, self.device)\n","            self.validation(\n","                self.test_loader, self.model,\n","                self.valid_metrics, self.device)\n","            total_train_metrics = self.train_metrics.compute()\n","            total_valid_metrics = self.valid_metrics.compute()\n","            print(f\"Training metrics for epoch {epoch}: {total_train_metrics}\")\n","            print(f\"Validation metrics for epoch {epoch}: {total_valid_metrics}\")\n","\n","            for metric, value in total_train_metrics.items():\n","                self.writer.add_scalar(f'Train/{metric}', value, epoch)\n","            for metric, value in total_valid_metrics.items():\n","                self.writer.add_scalar(f'Test/{metric}', value, epoch)\n","\n","            self.train_metrics.reset()\n","            self.valid_metrics.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2536530,"status":"ok","timestamp":1685639458165,"user":{"displayName":"Tom Ließmann","userId":"02644731503283882269"},"user_tz":-120},"id":"7IpbCyKKQxu8","outputId":"da5c730b-9566-45ac-bb7e-6a51354fe386"},"outputs":[],"source":["params = {\n","    'n_epochs': epochs,\n","    'train_loop': basic_training_loop,\n","    'validation_loop': metrics_validation,\n","    'model': model,\n","    'train_loader': train_loader,\n","    'test_loader': test_loader,\n","    'loss': nn.CrossEntropyLoss(),\n","    'optim': optim.SGD(model.parameters(), lr=learning_rate),\n","    'metrics' : {\n","        'train' : MetricCollection([\n","            Accuracy(task='binary'),\n","            AUROC(task='binary'),\n","            Precision(task='binary')]),\n","        'valid' :  MetricCollection([\n","            Accuracy(task='binary'),\n","            AUROC(task='binary'),\n","            Precision(task='binary')])\n","    },\n","    'device': device\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%reload_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%tensorboard --logdir=TF_LOGDIR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optim_loop = OptimizationLoop(params)\n","optim_loop.optimize()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMngjoREbVLuP5WTn6w1NnE","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
